{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfRd/Me1KnqHZV9ujcg27v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arakenufersa/IA/blob/main/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ang4LAMLrtEy"
      },
      "outputs": [],
      "source": [
        "!apt-get install graphviz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Carregando os dados**"
      ],
      "metadata": {
        "id": "VkeyQUyi9Q3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4ukZJvCnahy"
      },
      "outputs": [],
      "source": [
        "# Importando bibliotecas necessárias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from scipy.io import arff\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import graphviz\n",
        "\n",
        "# Fazer upload do arquivo ARFF\n",
        "uploaded = files.upload()\n",
        "\n",
        "# O nome do arquivo é a chave no dicionário uploaded\n",
        "filename = next(iter(uploaded))\n",
        "\n",
        "# Carregar o arquivo ARFF\n",
        "data, meta = arff.loadarff(filename)\n",
        "\n",
        "# Converter para DataFrame do pandas\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Exibir os primeiros registros do DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Identificar as colunas de atributos e a coluna de classe\n",
        "# (presumindo que a última coluna seja a coluna alvo, ajuste conforme necessário)\n",
        "X = df.iloc[:, :-1].values  # Todas as colunas exceto a última (atributos)\n",
        "y = df.iloc[:, -1].astype(str).values  # Última coluna (classe) convertida para string\n",
        "\n",
        "# Normalizar os dados (StandardScaler padroniza os dados com média 0 e desvio padrão 1)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)  # Normalizando todos os dados antes da validação cruzada\n",
        "\n",
        "# Exibir os primeiros registros do DataFrame\n",
        "print(X.view())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MLP com holdout com repetições**"
      ],
      "metadata": {
        "id": "K-qijcKHqp1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir o modelo MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(5,), activation='logistic', learning_rate='constant', learning_rate_init= 0.01, max_iter=1000, random_state=None)\n",
        "\n",
        "# Inicializar listas para armazenar as acurácias\n",
        "accuracies = []\n",
        "\n",
        "# Realizar Holdout com 30 repetições\n",
        "for i in range(30):\n",
        "    # Dividir os dados em treino (80%) e teste (20%)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)  # random_state=None para diferentes divisões\n",
        "\n",
        "    # Treinar o modelo\n",
        "    mlp.fit(X_train, y_train)\n",
        "\n",
        "    # Fazer previsões\n",
        "    y_pred = mlp.predict(X_test)\n",
        "\n",
        "    # Avaliar a acurácia do modelo\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Calcular a média e o desvio padrão das acurácias\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "std_accuracy = np.std(accuracies)\n",
        "\n",
        "# Exibir os resultados\n",
        "print(f\"Acurácia média do MLP (Holdout com 30 repetições): {mean_accuracy * 100:.2f}%\")\n",
        "print(f\"Desvio padrão da acurácia: {std_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "09CjXQREqskz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MLP com validação cruzada**"
      ],
      "metadata": {
        "id": "vjWzLT6hpe7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir o modelo MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(5,), activation='logistic', learning_rate='constant', learning_rate_init= 0.01, max_iter=1000, random_state=None)\n",
        "\n",
        "# Realizar validação cruzada com 10 grupos\n",
        "cv_scores = cross_val_score(mlp, X, y, cv=10)\n",
        "\n",
        "# Calcular a média e o desvio padrão das acurácias\n",
        "mean_accuracy = np.mean(cv_scores)\n",
        "std_accuracy = np.std(cv_scores)\n",
        "\n",
        "# Exibir os resultados\n",
        "print(f\"Acurácia média do MLP (Validação Cruzada com 10 grupos): {mean_accuracy * 100:.2f}%\")\n",
        "print(f\"Desvio padrão da acurácia: {std_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "bjfpmEhQpwo5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}